.
# AI 조교용 DPO 데이터셋 구축 & 전공 기반 공모전 추천 챗봇

이 저장소는 GPT 응답 품질 향상을 위한 DPO 데이터셋 구축 프로젝트와  
사용자의 전공 정보를 기반으로 공모전을 추천하는 챗봇 시스템 구현을 포함합니다.

---

## 1. AI 조교용 DPO 데이터셋 구축

### 프로젝트 개요
GPT의 부정확한 응답을 구별하여 `chosen/reject` 쌍으로 구조화된  
DPO (Direct Preference Optimization) 학습용 데이터셋을 생성하는 프로젝트입니다.

### 주요 목표
- 오류 메시지를 기반으로 GPT 응답 평가 및 분류
- 잘못된 reject 응답을 rule-based로 필터링
- 정량 기준에 기반한 선택/거절 응답 구성

### 사용 기술 및 작업
- **도구**: HuggingFace, GPT, Python, JSONL
- **주요 작업**:
  - GPT API를 활용한 응답 생성 자동화
  - 오류 패턴 기반 `reject` 필터링 스크립트 구현
  - `chosen/reject` 쌍 데이터셋 구조 설계

### 배운 점
- 프롬프트 설계와 응답 검증 간 피드백 루프의 중요성
- 단순 생성이 아닌, 평가 가능한 데이터 구성 경험

### 주요 파일
- `dataset.jsonl` – 최종 데이터셋
- `reject_filter.py` – 자동 필터링 코드

---

## 2. 전공 맞춤 실시간 공모전 추천 챗봇

### 프로젝트 개요
사용자의 전공과 관심 키워드를 기반으로  
실시간 공모전 정보를 필터링하고 추천 사유까지 제공하는 챗봇 시스템입니다.

### 주요 목표
- 단순 키워드 추천에서 벗어나, 전공 기반 정교한 필터링
- GPT를 활용한 **추천 설명 생성** 및 멀티스텝 reasoning 설계

### 사용 기술 및 작업
- **도구/프레임워크**: Next.js, LangChain, FastAPI, JavaScript
- **핵심 로직**:
  1. 사용자 입력 수집
  2. 공모전 데이터 크롤링/정제
  3. cosine similarity 기반 필터링
  4. GPT로 자연어 추천 사유 생성
- 단일 에이전트 대비 **전공 일치도 87% 이상 향상**

### 배운 점
- 멀티스텝 논리 구조가 추천 품질에 미치는 영향 체감
- 단순 출력이 아닌, **설명 가능한 AI 시스템 설계** 중요성 인식

